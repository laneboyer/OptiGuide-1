{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e37b19",
   "metadata": {},
   "source": [
    "# Explorative Repository Agent\n",
    "\n",
    ">>> TODO: write a paragraph to explain what \"Explorative Repository Agent\" is.\n",
    "\n",
    "Author: Runlong Zhou, Beibin Li\n",
    "\n",
    "\n",
    "- Motivation: TODO\n",
    "- Warm-Start: we warm start the repo by reading some important files and architectures, and then summarize the findings inside the \"SUMMARY.txt\".\n",
    "- **NOTE**: we have not utilize any truncking or caching mechanism yet to save computational cost. So, the OpenAI API cost would be high if you use this code base. Please proceed with caution.\n",
    "\n",
    "Timeline\n",
    "- July, 2023: The original project idea and [code](https://github.com/BeibinLi/SPM/commit/d18392d5ffabdf1af621f392619bf9d0ce031437) are created during Runlong's 2023 summer internship at Microsofot Research. During the project, we used \"long-term\" and \"short-term\" external memory inside LLM agents to store and retrieve useful information. \n",
    "- August, 2023: We create the [Coffee Dataset](https://github.com/BeibinLi/Coffee_Roasting_Dataset) as a synthetic benchmark for supply chain products. \n",
    "- January, 2024: we re-implemented the pipeline with [AutoGen](https://github.com/microsoft/autogen) and included the research code into [OptiGuide](https://github.com/microsoft/OptiGuide). We also provide a simpler design without utilizing external memory mechanism. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Introduction: Why do we need exploration\n",
    "\n",
    "\n",
    "### Methodology\n",
    "\n",
    "\n",
    "### Related Work\n",
    "The idea in this notebook is similar to [GPT Code Interpreter](https://openai.com/blog/chatgpt-plugins), [InterCode](http://arxiv.org/abs/2306.14898), [Open Interpreter](https://github.com/KillianLucas/open-interpreter), and many other open source projects. Here, we provide a subset of important inspirations, because it is hard (and almost impossible) to provide an exhaustive list of related projects. \n",
    "\n",
    "Prior Work:\n",
    "- LLM: [Recursive summarization](http://arxiv.org/abs/2109.10862), \n",
    "- Prompting guidelines: [ReAct](https://arxiv.org/abs/2210.03629), [CoT](https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html)\n",
    "- LLM Tools: [AutoGen](https://github.com/microsoft/autogen), LangChain, AutoGPT, LlamaIndex\n",
    "\n",
    "Some concurrent studies:\n",
    "- Code editing: [Magicoder](http://arxiv.org/abs/2312.02120). [RepoAgent](https://github.com/LOGIC-10/RepoAgent)\n",
    "- Exploration with LLMs: [Explore-Instruct](http://arxiv.org/abs/2310.09168), [search engine with copilot](http://arxiv.org/abs/2311.01235)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e39627",
   "metadata": {},
   "source": [
    "### Installing this experimental notebook\n",
    "\n",
    "Install the explorer branch of OptiGuide:\n",
    "```bash\n",
    "pip install https://github.com/microsoft/OptiGuide/archive/explorer.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506d9dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca5b9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from optiguide.experimental.explorer import ProjectAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cabe16",
   "metadata": {},
   "source": [
    "## Example: Coffee Dataset\n",
    "\n",
    "We use the [Coffee Dataset](https://github.com/BeibinLi/Coffee_Roasting_Dataset) as the example application, where users\n",
    "\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/BeibinLi/Coffee_Roasting_Dataset ~/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baff83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1091b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c146ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252e314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400e474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91213c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0367d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
